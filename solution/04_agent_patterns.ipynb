{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Core Agent Patterns\n",
    "\n",
    "All agentic frameworks (LangChain, LangGraph, CrewAI, DSPy) use these **two patterns**:\n",
    "\n",
    "1. **Tool Binding**: LLM decides which tools to call\n",
    "2. **Structured Output**: LLM returns predefined schema\n",
    "\n",
    "This notebook shows both patterns in action."
   ],
   "id": "63a5e2db89d86188"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ],
   "id": "f6e9092d8260bee6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-openai"
   ],
   "id": "333d821b22111992"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T14:23:07.439377Z",
     "start_time": "2026-01-17T14:23:06.793763Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # loads .env file\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ],
   "id": "b97654386e66d7d0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 1: Tool Binding\n",
    "\n",
    "**Use case**: LLM needs to perform actions (search, calculate, call APIs)\n",
    "\n",
    "**Flow**:\n",
    "1. Define tools with `@tool` decorator\n",
    "2. Bind tools to LLM: `llm.bind_tools(tools)`\n",
    "3. LLM suggests which tools to call\n",
    "4. You execute the tools"
   ],
   "id": "f62d71004b6d85e8"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T14:23:11.232542Z",
     "start_time": "2026-01-17T14:23:11.224834Z"
    }
   },
   "source": [
    "# Step 1: Define tools\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "  \"\"\"Subtract two numbers.\"\"\"\n",
    "  return a - b\n",
    "\n",
    "@tool\n",
    "def divide(a: float, b: float) -> float:\n",
    "  \"\"\"Divide two numbers.\"\"\"\n",
    "  return a / b\n",
    "\n",
    "tools = [multiply, add, subtract, divide]"
   ],
   "id": "1a7538739787d4af",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T14:24:02.113347Z",
     "start_time": "2026-01-17T14:24:00.249810Z"
    }
   },
   "source": [
    "# Step 2: Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Step 3: LLM decides which tool to use\n",
    "response = llm_with_tools.invoke(\"What is 25 times 4?\")\n",
    "\n",
    "print(\"Tool Calls:\", response.tool_calls)"
   ],
   "id": "903f1a7d9bf407bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Calls: [{'name': 'multiply', 'args': {'a': 25, 'b': 4}, 'id': 'call_2l77LxQb9YsEGoRTmxlVCr8k', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T14:24:22.854169Z",
     "start_time": "2026-01-17T14:24:22.849377Z"
    }
   },
   "source": [
    "# Step 4: Execute the tool\n",
    "tool_call = response.tool_calls[0]\n",
    "tool_name = tool_call['name']\n",
    "tool_args = tool_call['args']\n",
    "\n",
    "# Find and run the tool\n",
    "tool_map = {t.name: t for t in tools}\n",
    "result = tool_map[tool_name].invoke(tool_args)\n",
    "\n",
    "print(f\"\\nResult: {result}\")"
   ],
   "id": "c89b65114705d04e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result: 100.0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key insight**: LLM only *suggests* tool calls. You must execute them."
   ],
   "id": "528c46c4c64d8c66"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 2: Structured Output\n",
    "\n",
    "**Use case**: Extract/parse data into a specific format\n",
    "\n",
    "**Flow**:\n",
    "1. Define Pydantic model (schema)\n",
    "2. Use `llm.with_structured_output(Model)`\n",
    "3. LLM returns validated typed objects"
   ],
   "id": "69877633a6c96ae8"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T14:24:57.668791Z",
     "start_time": "2026-01-17T14:24:57.664154Z"
    }
   },
   "source": [
    "# Step 1: Define schema\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"Person's full name\")\n",
    "    email: str = Field(description=\"Email address\")\n",
    "    age: int = Field(description=\"Age in years\")"
   ],
   "id": "51ecf007ebd84fd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T14:25:05.191920Z",
     "start_time": "2026-01-17T14:24:59.134781Z"
    }
   },
   "source": [
    "# Step 2: Create structured LLM\n",
    "extractor = llm.with_structured_output(Person)\n",
    "\n",
    "# Step 3: Extract data\n",
    "text = \"Hi, I'm Alice Johnson, 28 years old. Email: alice@example.com\"\n",
    "person = extractor.invoke(text)\n",
    "\n",
    "print(f\"Type: {type(person)}\")\n",
    "print(f\"Name: {person.name}\")\n",
    "print(f\"Email: {person.email}\")\n",
    "print(f\"Age: {person.age}\")"
   ],
   "id": "8ea16c111c549822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class '__main__.Person'>\n",
      "Name: Alice Johnson\n",
      "Email: alice@example.com\n",
      "Age: 28\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key insight**: You get typed Python objects, not strings or dicts!"
   ],
   "id": "b0c3d507a4392d8d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "| Pattern | Method | When to Use | Output |\n",
    "|---------|--------|-------------|--------|\n",
    "| Tool Binding | `.bind_tools()` | Need to perform actions | Tool call suggestions |\n",
    "| Structured Output | `.with_structured_output()` | Need to extract/parse data | Typed Python objects |\n",
    "\n",
    "### Examples\n",
    "\n",
    "**Use Tool Binding for:**\n",
    "- Search the web\n",
    "- Call APIs\n",
    "- Execute code\n",
    "- File operations\n",
    "\n",
    "**Use Structured Output for:**\n",
    "- Extract entities\n",
    "- Parse forms\n",
    "- Generate task lists\n",
    "- Classify text"
   ],
   "id": "41628ca9897b5f56"
  },
  {
   "cell_type": "markdown",
   "id": "wbg1hen3qie",
   "source": "## Framework Comparison\n\nAll frameworks use the two patterns above, but with different approaches:\n\n### LangGraph\n**What**: Low-level framework for building stateful multi-agent workflows\n\n**Pros:**\n- Full control over agent logic and state\n- Built-in persistence and checkpointing\n- Great for complex workflows with cycles and conditions\n- Explicit graph structure makes debugging easier\n\n**Cons:**\n- Steeper learning curve\n- More boilerplate code\n- Need to manually handle state management\n\n**When to use:** Complex multi-step workflows, need full control, production systems\n\n---\n\n### DSPy\n**What**: Optimization-focused framework that compiles prompts\n\n**Pros:**\n- Automatically optimizes prompts and tool use\n- Focus on what to do, not how (declarative)\n- Great for research and experimentation\n- Can improve performance without manual prompt engineering\n\n**Cons:**\n- Different paradigm (requires mindset shift)\n- Less mature ecosystem\n- Optimization can be slow\n- Less intuitive for traditional developers\n\n**When to use:** Research projects, need to optimize performance, willing to learn new paradigm\n\n---\n\n### CrewAI\n**What**: High-level framework with role-based agents\n\n**Pros:**\n- Very simple API, minimal boilerplate\n- Built-in agent roles and collaboration\n- Good for team-based workflows\n- Fast prototyping\n\n**Cons:**\n- Less control over internals\n- Opinionated architecture\n- Harder to debug complex issues\n- Limited customization\n\n**When to use:** Quick prototypes, team-based agents, don't need fine-grained control\n\n---\n\n### LangFlow\n**What**: Visual/no-code builder for LangChain workflows\n\n**Pros:**\n- Visual drag-and-drop interface\n- No coding required for basic flows\n- Great for demos and exploration\n- Easy to share workflows\n\n**Cons:**\n- Limited to pre-built components\n- Hard to version control\n- Not suitable for complex logic\n- Performance overhead\n\n**When to use:** Demos, non-developers, rapid experimentation, visual learners\n\n---\n\n## Quick Decision Guide\n\n```\nNeed full control + complex logic? → LangGraph\nWant to optimize performance? → DSPy\nNeed quick prototype with teams? → CrewAI\nBuilding demo or learning? → LangFlow\nJust starting out? → LangChain (plain)\n```\n\n**Recommendation**: Start with plain LangChain to learn the patterns, then graduate to LangGraph for production.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
